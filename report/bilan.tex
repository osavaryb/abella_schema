\documentclass[nocopyrightspace,authoryear]{sigplanconf}
%\usepackage{fullpage}
\usepackage{natbib}
\usepackage{filecontents}
\usepackage{proof,enumerate,graphicx}
\usepackage{amsmath, amssymb}
%\usepackage{color}
\usepackage{exscale}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{multicol}
 \usepackage{stmaryrd}
\usepackage{url}
\usepackage{latexsym}
\usepackage{colonequals}

\renewcommand{\t}[1]{{\fontsize{1.0\zzlistingsize}{1.05\zzlistingsize}\texttt{#1}}}

% Set up listings "literate" keyword stuff (for \lstset below)
\newdimen\zzlistingsize
\newdimen\zzlistingsizedefault
\zzlistingsizedefault=8pt
\zzlistingsize=\zzlistingsizedefault
\global\def\InsideComment{0}
\newcommand{\Lstbasicstyle}{\fontsize{\zzlistingsize}{1.05\zzlistingsize}\ttfamily}
\newcommand{\keywordFmt}{\fontsize{0.9\zzlistingsize}{1.0\zzlistingsize}\bf}
\newcommand{\smartkeywordFmt}{\if0\InsideComment\keywordFmt\fi}
\newcommand{\commentFmt}{\def\InsideComment{1}\fontsize{0.95\zzlistingsize}{1.0\zzlistingsize}\rmfamily\slshape}

\newcommand{\LST}{\setlistingsize{\zzlistingsizedefault}}

\newlength{\zzlstwidth}
\newcommand{\setlistingsize}[1]{\zzlistingsize=#1%
\settowidth{\zzlstwidth}{{\Lstbasicstyle~}}}
\setlistingsize{\zzlistingsizedefault}
\renewcommand{\bar}{\overline}

\lstset{literate={->}{{$\rightarrow~$}}2 %
                 {=>}{{$\Rightarrow~$}}2 %
                 {id}{{{\smartkeywordFmt id}}}1 % 3 $~$
                 {\\Gamma}{{$\Gamma$}}1 %
                 {\\Pi}{{$\Pi$}}1 %
                 {\\Sigma}{{$\Sigma$}}1 %
                 {\\Pibox}{{$\Pibox$}}1 %
                 {\\psi}{{$\psi$}}1 %
                 {\\phi}{{$\phi$}}1 %
                 {\\sigma}{{$\sigma$}}1 %
                 {\\gamma}{{$\gamma$}}1 %
                 {mlam}{{$\lambda^{\scriptscriptstyle\Box}$}}1 %
%                 {mlam}{{$\lambda$}}1 %
                 {FN}{{$\Lambda$}}1 %
                 {<<}{\color{dGreen}}1 %
                 {>>}{\color{black}}1 %
               ,
               columns=[l]fullflexible,
               basewidth=\zzlstwidth,
               basicstyle=\Lstbasicstyle,
               keywordstyle=\keywordFmt,
               identifierstyle=\relax,
               xleftmargin=20pt,
%               stringstyle=\relax,
               commentstyle=\commentFmt,
               breaklines=true,
               breakatwhitespace=true,   % doesn't do anything (?!)
               mathescape=true
               }


\title{Automated reasoning with contexts in Abella}


\authorinfo{Olivier Savary-Belanger}
           {McGill University}
           {osavary@cs.mcgill.ca}

% \authorinfo{Kaustuv Chaudhuri}
%            {INRIA Saclay Ile-de-France}
%            {kaustuv.chaudhuri@inria.fr}




\begin{document}
\maketitle
\section{Introduction}
This work aims at simplifying reasoning with contexts in Abella.

Abella \cite{abellasys, abellanew} is an interactive theorem prover developed in a collaboration between INRIA Saclay Ile-de-France and U. of Minnesota. A formal development in Abella consists of:
\begin{itemize}
\item a specification file, where the studied systems and their meta-theory are defined.
\item a reasoning file, where theorems about the specifications are stated and proved using a language of tactics.
\end{itemize}

Abella allows for higher-order reasoning; terms may introduce assumptions to a local context of assumptions. In Abella, such contexts are represented as lists. However, reasoning with contexts generally requires a certain number of structural properties of the contexts which do not hold in general for lists of formulas. For this reason, other systems such as Twelf \cite{twelfsys} and Beluga \cite{belugasys} provide specific facilities to characterize contexts in such a way that the desired proprieties always hold. Instead, Abella users need to define a proposition characterizing what kind of assumption can dynamically extend the context, and prove a number of structural theorems to reason about members of such contexts.
% Our main contribution is to automatically prove properties about contexts defined using our facilities.
Generally speaking, such contexts tend to have a regular structure. In this work, we extend Abella with a mechanism for declaring such regular contexts in such a way that the standard properties of such contexts can be automatically derived.
% lacks specific facilities to define them, such as regular worlds in Twelf \cite{twelfsys} and schemas in Beluga \cite{belugasys}. 

\section{The Ctx Plugin by Example}

% We developed a plugin for Abella introducing \lstinline{Schema}, which restricts regular contexts definition to a fragment of inductive definitions available in Abella, and tactics automatically proving and applying theorems which always hold for context defined in our fragment. 
This work extends Abella with a new definition mechanism, called \lstinline{Schema}, that is used to specify a regular subset of inductively definitioned specification contexts. Regularity allows us to automatically derive a number of standard properties of such contexts that are part of the standard boilerplate of most Abella developments.
%
This extension is encapsulated in the form of a \emph{plugin} named \lstinline{Ctx}.
%
In this section we demonstrate the features of the \lstinline{Ctx} plugin by means of examples drawn from the \lstinline{breduce} development in Abella 2.0; specifically, we will focus on the \lstinline{ctx2} relation summarized below in standard syntax.

\begin{lstlisting}
kind tm, p   type.
...
type bred tm -> tm -> o.
type path tm -> p -> o.
type bfree tm -> o.
\end{lstlisting}
\begin{lstlisting}
Define ctx2 : olist -> olist -> prop by
  ctx2 nil nil
; nabla n p,
    ctx2 (bred n n :: G) (path n p :: D) := 
      ctx2 G D
; nabla n,
    ctx2 ((pi u\ bred M u => bred n u) :: G)
         ((pi q\ path M q => path n q) :: D) :=
      ctx2 G D.
\end{lstlisting}

%Top_command
Contexts, as defined in our plugin, can be described as zero or more formulas, each of a form given one of the clause from a finite set of clauses. N-ary context relations, where formulas (potentially depending on the same variables) are introduced simultaneously in  $n$ different contexts, can also be represented using our extension. The definition of \lstinline|ctx2| as a context relation schema is given below.

\begin{lstlisting}
Ctx !
Schema ctx2 := nabla n p, (bred n n, path n p);
               exists M, nabla n, 
                 ((pi u\ bred M u => bred n u), 
                 (pi q\ path M q => path n q)). !.
\end{lstlisting}


%Command


The tactics introduced by our plugin are:
\begin{itemize}
\item Inversion, which states that we can characterize members of the contexts by one of the clauses which could have introduced them. The inversion theorems we generate also provide information about the nominally quantified variables, and about the formulas introduced in the other projections of the context relation.

\begin{lstlisting}
Theorem ctx2_inversion_G :
forall G D F,
  ctx2 G D -> member F G ->
  ((exists N P, 
    member (path N P) D $\wedge$
    F = bred N N $\wedge$  
    name_p P $\wedge$ name_tm N)
  $\vee$
   (exists M N, 
    member (pi q\ path M q => path N q) D $\wedge$ 
    F = (pi u\ bred M u => bred N u) $\wedge$  
    fresh_tm_in_tm N M)).
intros Hctx  Hmem. 
Ctx ! inversion Hctx Hmem. !.
search.
\end{lstlisting}

\item Synchronize, which states that given a member of a context in a context relation, the clauses which could have introduced that term introduces, at the same time, the corresponding members in the other projections of the context relation.
\begin{lstlisting}
Theorem ctx2_synchronize :
  forall G D M N,
  ctx2 G D ->
  member (pi u\ bred M u => bred N u) G ->
  (member (pi q\ path M q => path N q) D $\wedge$ 
   fresh_tm_in_tm N M).
intros Hctx Hmem. 
Ctx ! sync Hctx Hmem. !.
search.
\end{lstlisting}

\item Unique, which states that two members of a context sharing nominal variables bound in the schema should be equal. This is because we restrict the logical variables to be bound before the nominal variables introduced in each clauses, such that the nominal variables can only appear within the formulas from the clause that introduced them. 

\begin{lstlisting}
Theorem member_D_unique :
   forall G D X Y N,
   ctx2 G D ->
   member (pi q\ path X q => path N q) D ->
   member (pi q\ path Y q => path N q) D ->
   X = Y.
intros Hctx Hmem1 Hmem2. 
Ctx ! unique Hctx Hmem1 Hmem2. !. 
search.
\end{lstlisting}

\item Projection, which helps reusing contexts in different context relations by verifying and applying transformation (projections and injections) theorems between context relations. Intuitively, the $i$th projection of context relation \lstinline|S| can be used as the $j$th projection of a context relations \lstinline|S'| only if the $j$th projection of the schema \lstinline|S'| is more general than the $i$th projection schema \lstinline|S|.

\begin{lstlisting}
Ctx !
Schema bctx := exists M, nabla n, 
                  (pi u\ bred M u => bred n u);
               exists n n', bred n n'. !.


Theorem ctx2ToBctx: forall E D, ctx2 E D -> bctx E.
intros Hctx. 
Ctx ! projas (bctx E) Hctx. !.
search.

Ctx ! Schema pctx := nabla n p, path n p. !.

Theorem pctxToCtx2: forall D, pctx D -> 
    (exists E, ctx2 E D).
intros Hctx. 
Ctx ! projas (ctx2 E D) Hctx. !. 
search.

\end{lstlisting}


\end{itemize}

\section{The Ctx Plugin Revisited}
\subsection{Plugin}
The extension we describe adds both top level commands and tactics to Abella. Instead of modifying the parser and main function to support the new functionality, we devised a plugin framework where an arbitrary expression can be dispatched to a particular plugin from an Abella source file. The signature of plugin modules is provided below.

\begin{lstlisting}

module type PLUGIN = sig 
  val process_tactic : 
       (string -> Prover.sequent) 
       -> string 
       -> Prover.sequent 
       -> unit
  val process_top : 
       (string -> unit) 
       -> string 
       -> unit
end

\end{lstlisting}

Plugins are implemented as modules implementing a processing function for strings received from the top level of the source file, and another processing function for strings received as reasoning command. Each processing function receives a function which allows to recursively process strings as if their appeared in their respective position in the source file. The processing function at the reasoning command level also receives a copy of the current goal and hypothesis, which are updated by their recursing function.

\begin{lstlisting}
TOP_COMMAND :=
 | ...
 | <PLUGIN-NAME> ! <STRING> !.

TACTICS :=
 | ...
 | <PLUGIN-NAME> ! <STRING> !.
\end{lstlisting}



\subsection{Top level command}
The grammar of the schema definitions follows.

\begin{lstlisting}
TOP_COMMAND :=
  | Schema <SCH-NAME> := <CLAUSES>.

CLAUSES :=
  | <CLAUSE>
  | <CLAUSE>; <CLAUSES>

CLAUSE :=
  | <OPTEXISTS> <OPTNABLAS> ( <CBODY> )
  | <OPTEXISTS> <OPTNABLAS> <OPTTERM>

OPTEXISTS :=
  | exists <ID LIST>, 
  |

OPTNABLAS :=
  | nabla <ID LIST>,
  |

CBODY :=
  | <OPTTERM>, <CBODY>
  | <OPTTERM>

OPTTERM :=
 | <TERM>
 | 
\end{lstlisting} 

\subsubsection{Schema}
A context, as defined by our extension, can be represented as \lstinline|($\sum_{i=1}^n$ (F$_{i,1}$, ..., F$_{i,m}$))$^*$|, where each \lstinline|F$_{i,j}$| is either a formula or empty. 

A Schema definition consists of a series of clauses separated by semi-colon and terminated with a colon. Each clause consists of a tuple of formulas, their free variable bound either in existential ($\exists$) or  nominal ($\nabla$) quantifiers heading the clause. We restrict the order of quantification to a series of $\exists$ followed by a series of $\nabla$, such that the nominal variables introduced in a clause cannot appear in the clause's logic variables , the latter being bound outside the scope of the nominal abstractions. We take the length and projections of the tuple as length and projections of the clause.

A Schema definition \lstinline|ctxM| is well-formed if each of its clauses have the same length $m$. In that case, it can be expanded as an inductively-defined Abella proposition of type \lstinline|olist -> ... ->  prop| with $m$ olist. To this definition is added a base case \lstinline|ctxM nil ... nil| (with $m$ \lstinline|nil|), and, for each clause, a case saying that given a context relation \lstinline|ctxM G$_1$ ... G$_m$|, it can be extended by adding the formula in the $i$th projection of the clause in front of \lstinline|G$_i$|.
\begin{lstlisting}
$\exists$ A$_1$ ... A$_p$, $\nabla$ n$_1$ ... n$_q$, (F$_1$, ..., F$_m$)

$\leadsto$

nabla n$_1$ ... n$_q$, ctxM F$_1$::G$_1$ ... F$_m$::G$_m$ := 
                       ctxM G$_1$ ... G$_m$
\end{lstlisting}

Context relations defined using schema are added to the definitions of the Abella session as any other inductive definition, and can thus afterward be referred to and be reasoned about in the same way as any other Abella proposition.

\subsubsection{Generated Lemmas}

After a Schema is defined, in addition to the context relation proposition being defined, a number of propositions and lemmas are automatically generated.

For each unique pair of types \lstinline|(t$_1$,t$_2$)| where \lstinline|t$_1$| is the type of a nominal variable and \lstinline|t$_2$| is the type of a logic variable appearing in the same clause, we define a proposition \lstinline|fresh_t$_1$_in_t$_2$ N X|, stating that \lstinline|N| is a $\nabla$-bound variable of type \lstinline|t$_1$| which can't appear in \lstinline|X|.

\begin{lstlisting}
Define fresh_t1_in_t2 : t1 -> t2 -> prop by
  nabla n, fresh_t1_in_t2 n X.
\end{lstlisting}

If no logic variable appears in the clause, we instead define \lstinline|name_t$_1$ N|, stating that \lstinline|N| is a nominal variable of type \lstinline|t$_1$|.

\begin{lstlisting}
Define name_t1: t1 -> prop by
 nabla n, name_t1 n.
\end{lstlisting}

Finally, for each \lstinline|t$_1$|, a prune lemma is stated and proved. The statement of the pruning theorem for type \lstinline|t$_1$| is given below.
% this needs to be done as, while logic quantifiers are polymorphic at the reasoning level, this is not the case of nominal quantifiers.
\begin{lstlisting}
Theorem member_prune_t1 : forall G E, nabla (n:t1), 
    member (E n) G -> (exists E', E = x\E').
\end{lstlisting}

\subsection{Tactics}
The grammar for the tactics supported by our plugin follows.
\begin{lstlisting}
TACTICS :=
  | inversion <HYP-NAME> <HYP-NAME>.
  | sync      <HYP-NAME> <HYP-NAME>.
  | unique    <HYP-NAME> <HYP-NAME> <HYP-NAME>.
  | projas ( <TERM> )  <HYP-NAME>.
\end{lstlisting}

\subsubsection{Inversion}
\label{subsec:inv}

The \lstinline|inversion| tactic expects two hypotheses, the first of the form \lstinline|ctxM G$_1$ ... G$_m$| and the second of the form \lstinline|member E G$_i$|, where \lstinline|E,G$_1$,...,G$_m$| are arbitrary logic variables,\lstinline|ctxM| is a defined schema of arity $m$ and \lstinline|1 $\leq$ $i$ $\leq$ $m$|.

The statement generated by the \lstinline|inversion| tactic concludes, given the two hypothesis, in a disjunction, each of its component corresponding to a clause \lstinline|C$_j$| in the schema \lstinline|ctxM| which could have introduced \lstinline|E| in \lstinline|G$_i$|. Each component is a conjunction of the information given by each projection of \lstinline|C$_j$|. Where \lstinline|C$_{j,k}$| is the formula at the $k$th projection of the clause \lstinline|C$_j$|, if $k=i$, then we know that \lstinline|E = C$_{j,k}$|, otherwise \lstinline|member C$_{j,k}$ G$_k$|. Moreover, for every pair of nominal \lstinline|n| of type \lstinline|nt| and logical variables \lstinline|E'| of type \lstinline|et| in the clause, we add \lstinline|fresh_nt_in_et n E'| to the component, asserting that \lstinline|n| is $\nabla$-bound and doesn't appear in \lstinline|E'|. In the case where no logical variable are $\exists$-bound in the clause, we instead add \lstinline|name_nt n|, asserting that \lstinline|n| is nominal.

\subsubsection{Synchronize}
Synchronize can be seen as generalization of inversion, removing the requirement that \lstinline|E| is logic variable. 

The \lstinline|sync| tactic expects two hypotheses, the first of the form \lstinline|ctxM G$_1$ ... G$_m$| and the second of the form \lstinline|member F G$_i$|, where \lstinline|F| is a formula, \lstinline|G$_1$,...,G$_m$| are arbitrary logic variables,\lstinline|ctxM| is a defined schema of arity $m$ and \lstinline|1 $\leq$ $i$ $\leq$ $m$|.

The statement generated by the \lstinline|sync| tactic concludes in a disjunction with a component for each clause \lstinline|C$_j$| such that $\exists \sigma.$ \lstinline| [$\sigma$] C$_{j,k}$ $=$ F|, which is to say that \lstinline|F| matches the pattern \lstinline|C$_{j,k}$|. Such a component will then be a conjunction of, for $k \neq i$, \lstinline|member C$_{j,k}$ G$_k$|, in addition to the \lstinline|fresh_in| or \lstinline|name| assumptions described in ~\ref{subsec:inv}.

\subsubsection{Unique}
The \lstinline|unique| tactic expects three hypotheses, the first of the form \lstinline|ctxM G$_1$ ... G$_m$|, the second of the form \lstinline|member F$_1$ G$_i$| and the third of the form \lstinline|member F$_2$ G$_i$|, where \lstinline|F$_1$,F$_2$| are unifiable formulas, \lstinline|G$_1$,...,G$_m$| are arbitrary logic variables,\lstinline|ctxM| is a defined schema of arity $m$ and \lstinline|1 $\leq$ $i$ $\leq$ $m$|.

The \lstinline|unique| theorems are based on the observation that, due to our binding order, a particular nominal variable can only appear in a single clause of the context relation. Therefore, we can validly state the theorems that, if \lstinline|F$_1$| and \lstinline|F$_2$| share a nominal variable bound by the schema, and that they are both from the same projection of \lstinline|ctxM|, it must be that \lstinline|F$_1$ = F$_2$|. To create the statement of the theorem, we unify \lstinline|F$_1$| and \lstinline|F$_2$| as \lstinline|F|, and create a set \lstinline|S| of all clauses \lstinline|C$_l$| of \lstinline|ctxM| for which \lstinline|C$_{l,i}$| would match \lstinline|F|. Then, we see if there exists a logic variable \lstinline|E| appearing at the same position in \lstinline|F$_1$| and \lstinline|F$_2$|, such that, in each \lstinline|C$_{l,i}$ $\in$ S|, a nominal variable appears at this position. If this is the case, the statement will consists of, given the original \lstinline|ctxM G$_1$ ... G$_m$| hypothesis and two assumptions \lstinline|member F'$_1$ G$_i$| and \lstinline|member F'$_2$ G$_1$|, where \lstinline|F'$_1$, F'$_2$| are formulas of the form corresponding to unifying all \lstinline|C$_{l,i}$ $\in$ S| together, solely sharing the logical variable \lstinline|E| and whose other variables are, respectively, \lstinline|A$_1$, ..., A$_p$| and \lstinline|B$_1$, ..., B$_p$|, then \lstinline|A$_j$ = B$_j$| for $1 \leq j \leq p$.



\subsubsection{Projection}
The \lstinline|projection| tactic expects a formula of the form \lstinline|ctxP D$_1$ ... D$_p$| and an hypothesis of the form \lstinline|ctxM G$_1$ ... G$_m$|, where \lstinline|ctxM| and \lstinline|ctxP| are defined schemas respectively of arity $m$ and $p$, and \lstinline|D$_1$,...,D$_p$|, \lstinline|G$_1$,...,G$_m$| are sets of logic variables, possibly overlapping.

Most of the work done in the \lstinline|projection| tactic is to verify that \lstinline|ctxM G$_1$ ... G$_m$| does indeed imply \lstinline|ctxP D$_1$ ... D$_p$|, which is to say that there exists a transformation from any context of the original schema \lstinline|ctxM| to one of the destination schema \lstinline|ctxP|.

To do so, for each clause \lstinline|C$_i$| from \lstinline|ctxM|, we create a list of constraints which arise from introducing formulas to the context using that clause, respecting the possible repetitions of context variables in \lstinline|G$_1$, ..., G$_m$|. For example, if the \lstinline|$j$th| and the \lstinline|$k$th| projection of \lstinline|ctxM| share the same context variable \lstinline|G|, and \lstinline|C$_{i,k}$ = of x A,  C$_{i,j}$ = of x (foo B)|, then the constraints added would be \lstinline|(G,of x (foo C))|. However, if one of \lstinline|C$_{i,j}$| or \lstinline|C$_{i,k}$| didn't introduce a formula and the other did, or if they added formulas which aren't unifiable, then we consider that this clause couldn't have been used to build the original relation, and return an empty constraints list for that clause.

Then, for each clause \lstinline|C$_i$| from \lstinline|ctxM|, we verify that there exists a clause in \lstinline|ctxP| which satisfies the constraints list \lstinline|S$i$| given by \lstinline|C$_i$|, which is to say that there is a more general clause of \lstinline|ctxP| which can handles the formulas introduced by \lstinline|C$_i$|. We create a list of constraints \lstinline|S'$j$| from the clause \lstinline|C$_j$| of \lstinline|ctxP| as we did it for \lstinline|ctxM|, and we verify that if it satisfies all constraints from the original clause. In short, given the constraints from \lstinline|ctxM| and \lstinline|ctxP|, for the transformation to be proven by our extension, it must be that the following is true:
\begin{lstlisting}
 $\forall$ S$_i$. $\exists$ S'$_j$. 
   $\forall$ (g,tm) $\in S_i$. $\forall$ (g',tm') $\in$ S'$_j$. 
     (g' = g) $\rightarrow (\exists \sigma$. [$\sigma$] tm' = tm)
\end{lstlisting}



\begin{comment}
2:
To do so, for every \lstinline|D$_i$ $\in$ D$_1$, ..., D$_p$|, we form the set 
\lstinline|S$_{i}$: { G$_k$ $\mid$ D$_i$ = G$_k$ $\wedge$ G$_k$ $\in$ G$_1$, ..., G$_m$}|. 
Then, for each such \lstinline|S$_i$| and for each clause \lstinline|C$_j$| in the original schema \lstinline|ctxM|, we unify, for each \lstinline|G$_k$ $\in$ S$_i$|, \lstinline|C$_{j,k}$| together as \lstinline|CR$_{i,j}$| , and verify that there exists a clause \lstinline|C'$_l$| in the destination schema \lstinline|ctxP| such that \lstinline|CR$_{i,j}$| matches \lstinline|C'$_{l,i}$|.
\end{comment}

\begin{comment}
1:
The $i$th context relations \lstinline|S| can be used as the $j$th projection of a context relations \lstinline|S'| if, for each clauses \lstinline|C| of \lstinline|S|, there exists a clause \lstinline|C'| of \lstinline|S'| s.t. the $i$th formula of \lstinline|C| matches the $j$th formula of \lstinline|C'|, which is to say that the $j$th projection of the schema \lstinline|S'| is more general than the $i$th projection schema \lstinline|S| .
\end{comment}


\section{Discussion and Conclusion}
Our tactics eliminate the need for boilerplate lemmas present in the developments from the Abella example suite. For example, using our plugin to rewrite the \lstinline{bredure} example eliminates $40\%$ of the lines of code in the reasoning (\lstinline{.thm}) file. As additional context relations and mappings between context relations are present in bigger developments, we believe the provided tactics can significantly reduce the overhead of reasoning with contexts in a Abella developments.


\begin{center}
\begin{tabular} { | c || p{1.5cm} | p{1.5cm} | p{1.5cm} |}
\hline
File & Schema used & Lemmas generated & LOC removed \\ \hline
type-uniq & 1 & 3 & 27  \\ \hline
copy & 1 & 4 & 28 \\ \hline
breduce & 3 & 11 & 124 \\ \hline

\end{tabular}
\end{center}

All the theorems proved by the tacticals could be proven at the moment of schema definition (or when the second schema is defined, in the case of projection). To reduce the number of theorems polluting the environment, we state and prove them only as needed, selecting the required theorem by observing the assumptions applied to the tactics. Proven theorems are kept until the end of the proof in which the tactical was used to avoid having to reprove them, for example in the case of repetitive application of a tactic to similar hypothesis. Each theorem can be named by stating it and using a tactical to prove it, as shown in each of the included example use of tacticals.

%limitation
Our schema definitions do not cover all the possible uses of contexts in Abella. 
For example, we limit the right hand side on the definition to the smaller context relation, where some developments include, for example, propositions about the terms being added. We also only allow at most one formula to be added to each projection of the context, where some developments add multiple formulas at the same time on top of a context, which is required in the case where a term in that context refers to multiple clauses sharing a single nominal variable. % As an alternative, one could define their own tuples and use them to combine multiple formulas as one. 
 
As for the tactics, we only generate the theorems and their proofs when we are convinced the theorems are true. This also means we refuse to generate a theorem when it falls outside of the fragment verified in our implementation of the tactics. The projection tactic, for example, only verifies if formulas introduced by a \emph{single} clause of the original schema could have been introduced by a \emph{single} clause of the destination schema. One theorem falling outside its verified fragment is the projection from \lstinline|ctxO G G| to  \lstinline|ctxD G G| with
\begin{lstlisting}
Schema ctxD := (i, i).

Schema ctxO := (i,  );
               ( , i).
\end{lstlisting}

%For example, it can't infer constraints arising from non-overlapping clauses having to interact in particular ways due to repeated context variable, as would be needed to verify 

%Related work
An important design decision of our development is that the theorems generated are proven using the primitive tactics of Abella, and verified as regular theorems. Consequently, no logical inconsistency could have been introduced by our plugin. This contrasts with theorem provers providing primitive notions of context, such as Twelf \cite{twelfsys} and Beluga \cite{belugasys}, where the properties proven with our tactics are part of the trusted code base.

%Ctx future work
Another valuable operation when reasoning with contexts is schema subsumption. To implement schema subsumption, we would first need to infer a subordination relation from the signature, as done in Twelf \cite{twelfsys}. Intuitively, subordination tells you the types of terms which can appear within another term of a given type. Using the subordination relation, we can determine when a theorem can be used with a context of a different schema, schema subsumption. A satisfying solution might include working \emph{by default} in the minimal schema in which we can reason about terms of a given type and inferring all places where subsumption is needed, which can't be done using plugins as we define them.


%Plugin future work
 That \lstinline|process_tactic| can observe the current sequent can be related to tactical languages such as Ltac \cite{ltacpap}, which can be used to develop Coq procedures applying tactics in function of current goal. In comparison, we allow arbitrary, potentially unsafe Ocaml code in the plugins, with the restriction that the only entry point back in the prover is the passed function. In the future, one would like to provide functions for plugins to safely interact with the prover, which could culminate in a language to define extensions and tacticals from within Abella source files. In a redevelopment of Abella, one could think of tactics solely as plugins, using a set of primitive, trusted operations on the current sequent to implement them, which would result in a prover with a smaller trusted code base.




 \bibliographystyle{abbrvnat}

 \bibliography{summer}


\end{document}
